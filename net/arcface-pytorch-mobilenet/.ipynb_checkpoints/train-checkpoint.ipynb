{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from MobileNetV2 import MobileNetV2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the whole dataset is 202599\n",
      "use 10910/202599\n",
      "C:\\Users\\hzhao\\Desktop\\dataset\\celebA dataset\\img_align_celeba\\000001.jpg\n"
     ]
    }
   ],
   "source": [
    "#制作训练集，celebA数据集，人脸图片和对应的身份，是大概1-10000多的数字\n",
    "\n",
    "train_data=r'C:\\Users\\hzhao\\Desktop\\dataset\\celebA dataset'\n",
    "train_img_dir=os.path.join(train_data,'img_align_celeba')\n",
    "train_identity_path=os.path.join(train_data,'identity_CelebA.txt')\n",
    "\n",
    "with open(train_identity_path,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    img_list = [os.path.join(train_img_dir, i.split()[0]) for i in lines]\n",
    "    identity_list = [i.split()[1] for i in lines]\n",
    "\n",
    "print('length of the whole dataset is '+str(len(identity_list)))\n",
    "\n",
    "def default_loader(img):\n",
    "    return Image.open(img)\n",
    "\n",
    "class train_set(Dataset):\n",
    "    def __init__(self):\n",
    "        self.img=[]\n",
    "        self.iden=[]\n",
    "        self.loader=default_loader\n",
    "        self.transform=transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        for i in range(len(img_list)):\n",
    "            if int(identity_list[i])<500:\n",
    "                self.img.append(img_list[i])\n",
    "                self.iden.append(int(identity_list[i]))\n",
    "    def __getitem__(self,index):\n",
    "        img_path=self.img[index]\n",
    "        iden=self.iden[index]\n",
    "        img=self.loader(img_path)\n",
    "        img=self.transform(img)\n",
    "        return img,iden\n",
    "    def __len__(self):\n",
    "        return len(self.iden)\n",
    "\n",
    "train_dataset=train_set()\n",
    "train_loader=DataLoader(train_dataset,batch_size=10)\n",
    "print(\"use \"+str(len(train_dataset))+\"/\"+str(len(identity_list)))\n",
    "print(img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use 7701 pics, and 6000 pairs\n",
      "Abel_Pacheco/Abel_Pacheco_0001.jpg\n",
      "C:\\Users\\hzhao\\Desktop\\dataset\\LFW dataset\\lfw_funneled\\Abel_Pacheco/Abel_Pacheco_0001.jpg\n"
     ]
    }
   ],
   "source": [
    "#制作test集，LFW数据集，好像不用dataloader，要自己写一个，先借用别人的test.py代码吧\n",
    "#这里只是把图片列表读出来\n",
    "#需要加载图片、获得特征、计算距离等等\n",
    "#还不知道距离的阈值怎么确定\n",
    "\n",
    "test_data=r'C:\\Users\\hzhao\\Desktop\\dataset\\LFW dataset'\n",
    "test_img_dir=os.path.join(test_data,r'lfw_funneled')\n",
    "test_pair=os.path.join(test_data,'lfw_test_pair.txt')\n",
    "\n",
    "#使用的图片的合集，使用model计算后得到feature_list\n",
    "with open(test_pair,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    test_img_list=[]\n",
    "    count=0\n",
    "    for i in lines:\n",
    "        splits=i.split()        \n",
    "        count=count+1\n",
    "        if splits[0] not in test_img_list:\n",
    "            test_img_list.append(splits[0])\n",
    "\n",
    "        if splits[1] not in test_img_list:\n",
    "            test_img_list.append(splits[1])\n",
    "\n",
    "test_img_path=[os.path.join(test_img_dir, i) for i in test_img_list]\n",
    "print('use '+str(len(test_img_list))+' pics, and '+str(count)+ ' pairs')\n",
    "print(test_img_list[0])\n",
    "print(test_img_path[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从零开始训练模型\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "EPOCHS=5\n",
    "net = MobileNetV2(n_class=2)\n",
    "model= MobileNetV2(n_class=2).to(DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3(myenv)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
